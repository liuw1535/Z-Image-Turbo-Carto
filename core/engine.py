# -*- coding: utf-8 -*-
"""
æ¨ç†å¼•æ“ (APIé€‚é…ç‰ˆ)
è´Ÿè´£æ¨¡å‹çš„åŠ è½½ã€æ˜¾å­˜ä¼˜åŒ–åŠå›¾ç‰‡ç”Ÿæˆã€‚
è¿”å›ç»“æ„åŒ–æ•°æ®è€Œé UI å­—ç¬¦ä¸²ã€‚
"""
import torch
from diffusers import DiffusionPipeline # type: ignore
import gc
import time
from core.utils import detect_device, get_torch_dtype
from core.lora_manager import LoRAMerger
import config

class ZImageEngine:
    def __init__(self):
        self.pipe = None
        self.device = None
        self.dtype = None
        self.lora_merger = None
        self.current_lora_applied = False

    def is_loaded(self):
        return self.pipe is not None

    def load_model(self):
        """åŠ è½½æ¨¡å‹ (è‡ªåŠ¨æ£€æµ‹è®¾å¤‡)"""
        self.device = detect_device()
        self.dtype = get_torch_dtype(self.device)
        
        print(f"ğŸš€ [Engine] æ­£åœ¨åŠ è½½æ¨¡å‹... è®¾å¤‡: {self.device.upper()}, ç²¾åº¦: {self.dtype}")
        
        # æ¸…ç†æ—§æ˜¾å­˜
        if self.pipe:
            del self.pipe
            self.pipe = None
            gc.collect()
            if torch.cuda.is_available(): torch.cuda.empty_cache()
            if torch.backends.mps.is_available(): torch.mps.empty_cache()

        try:
            self.pipe = DiffusionPipeline.from_pretrained(
                config.MODEL_PATH,
                torch_dtype=self.dtype,
                trust_remote_code=True,
            )
            self.pipe.to(self.device)
            
            self.lora_merger = LoRAMerger(self.pipe)
            self.current_lora_applied = False
            
            self._apply_optimizations()
            
            print("âœ… [Engine] æ¨¡å‹åŠ è½½å®Œæ¯•ã€‚")
            return True, f"å°±ç»ª ({self.device.upper()})"
            
        except Exception as e:
            print(f"âŒ [Engine] åŠ è½½å¤±è´¥: {e}")
            return False, str(e)

    def _apply_optimizations(self):
        """åº”ç”¨ä¼˜åŒ–ç­–ç•¥"""
        # VAE å¼ºåˆ¶ FP32
        if hasattr(self.pipe, "vae"):
            self.pipe.vae.to(dtype=torch.float32) # pyright: ignore[reportOptionalMemberAccess]
            self.pipe.vae.config.force_upcast = True # pyright: ignore[reportOptionalMemberAccess]

        # ç¡¬ä»¶ç‰¹å®šä¼˜åŒ–
        if self.device == "mps":
            # MPS æ˜¾å­˜è¶³å¤Ÿæ—¶å…³é—­ Tiling ä»¥è·å¾—æœ€ä½³ç”»è´¨
            pass 
        elif self.device == "cuda":
            self.pipe.enable_model_cpu_offload() # pyright: ignore[reportOptionalMemberAccess]
            if hasattr(self.pipe, "enable_vae_tiling"):
                self.pipe.enable_vae_tiling() # pyright: ignore[reportOptionalMemberAccess]

    def update_lora(self, enable, scale):
        """æ›´æ–° LoRA çŠ¶æ€"""
        if not self.is_loaded(): return
        
        # ç®€åŒ–é€»è¾‘ï¼šçŠ¶æ€å˜æ›´åˆ™é‡è½½æ¨¡å‹
        if (not enable and self.current_lora_applied) or (enable and self.current_lora_applied):
            print("ğŸ”„ [Engine] LoRA å˜æ›´ï¼Œé‡è½½æ¨¡å‹...")
            self.load_model()
            if enable:
                self.lora_merger.load_lora_weights(config.LORA_PATH, scale) # pyright: ignore[reportOptionalMemberAccess]
                self.current_lora_applied = True
        elif enable and not self.current_lora_applied:
            self.lora_merger.load_lora_weights(config.LORA_PATH, scale) # pyright: ignore[reportOptionalMemberAccess]
            self.current_lora_applied = True

    def generate(self, prompt, neg_prompt, steps, cfg, width, height, seed, seed_mode):
        """
        ç”Ÿæˆå›¾ç‰‡
        Returns:
            dict: { "image": PIL_Image, "seed": int, "duration": float }
        """
        start_time = time.time()
        
        # æ˜¾å­˜æ¸…ç†
        gc.collect()
        if self.device == "mps": torch.mps.empty_cache()
        if self.device == "cuda": torch.cuda.empty_cache()

        # ç§å­å¤„ç†
        if seed_mode == "random" or seed == -1:
            actual_seed = torch.randint(0, 2**32 - 1, (1,)).item()
        else:
            actual_seed = int(seed)
            
        gen_device = "cpu" if self.device == "mps" else self.device
        generator = torch.Generator(gen_device).manual_seed(actual_seed) # pyright: ignore[reportArgumentType]

        print(f"ğŸ¨ [Generate] å°ºå¯¸: {width}x{height} | æ­¥æ•°: {steps} | ç§å­: {actual_seed}")

        try:
            image = self.pipe(prompt=prompt,negative_prompt=neg_prompt,num_inference_steps=steps,guidance_scale=cfg,width=width,height=height,generator=generator).images[0] # type: ignore
            
            duration = time.time() - start_time
            
            return {
                "success": True,
                "image": image,
                "seed": actual_seed,
                "duration": round(duration, 2)
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }